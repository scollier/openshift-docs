[[refarch_details]]

== Components and Configuration

This chapter describes the reference architecture environment that is deployed which enables the configuration of a highly available OpenShift Compute Platform 3 environment on Amazon Web Services.

The image below provides a high-level representation of the components within this
reference architecture.  Using Amazon Web Services, resources are highly
available using a combination of multiple availability zones, Elastic Load Balancers,
and an S3 bucket. Instances deployed are given specific roles to support OpenShift.
The Bastion host limits the external access to internal servers by insuring that
all SSH traffic passes through the Bastion host. The master instances host the
OpenShift master components such as etcd and the OpenShift API.  The Application
instances are for users to deploy their containers while the Infrastructure
instances are used for the OpenShift Router and Registry.  Authentication is managed
by Google OAuth.  OpenShift on AWS has two cloud native storage options; Elastic Block
Storage are used for the filesystem of instances but can also be used for persistent 
storage in containers.  The other storage option is S3 which is object based storage. 
S3 is used for the persistent storage of the OpenShift Registry.

image::images/OSE-on-AWS-Architecture.png[]

This reference architecture breaks down the deployment into separate phases.

* Phase 1: Provision the infrastructure on AWS
* Phase 2: Dynamic inventory of the provisioned infrastructure
* Phase 3: Provision OpenShift Compute Platform on AWS
* Phase 4: Post deployment activities

For Phase 1, there are 2 options provided in this reference architecture. The first option is to provision the infrastructure using the AWS CLI, orchestrated via bash scripts that are provided in XXXXXXXXX github repo. The second option is to provision the infrastructure using a set of Ansible playbooks that are also provided in the same github repo.  The choice is yours, after the infrastructure is provisioned, via either method, the environment will be ready for phase 2 dynamic inventory.

NOTE: The scripts provided in the github repo are not supported by Red Hat. They merely provide a mechanism that can be used to build out your own infrastructure.

=== Elastic Compute Cloud Instance Details

Within this reference environment, the instances are deployed in multiple AZs in the us-east-1
region by default. It is advised but not required to create these instances using reserved instances.
Because most of the instances are running 24x7 using reserved instances will cut
down on cost.  It is advised to reserve instances 1 year at a time due to AWS price
breaks.  The instances deployed for the OpenShift environment are m4.large and
contain an extra disk used for Docker storage.  The bastion host is a t2.micro.
Instance sizing can be changed in the variable files for each installer.

=== Software Version Details

The following tables provide the installed software versions for the different servers that make up the Red Hat OpenShift highly available reference environment.

.RHEL OSEv3 Details
|====
^|Software ^|Version

|Red Hat Enterprise Linux 7.2 x86_64 | kernel-3.10.0-327
| atomic-openshift{master/clients/node/sdn-ovs} | 3.2.1.x
| docker | 1.10.x
| ansible | 1.9.x
| openshift ansible installer | branch: enterprise-3.2
|====


=== Required Channels

The following channels must be subscribed to in order to access the content needed to deploy this configuration.

.Required Channels - OSEv3 Master Servers
|====
^|Channel ^|Repository Name

| Red Hat Enterprise Linux 7 Server (RPMs) |
rhel-7-server-rpms | Red Hat OpenShift Enterprise 3.2 (RPMs) | rhel-7-server-ose-3.2-rpms
| Red Hat Enterprise Linux 7 Server - Extras (RPMs) | rhel-7-server-extras-rpms

|====

.Required Channels - OSEv3 Nodes
|====
^|Channel ^|Repository Name

| Red Hat Enterprise Linux 7 Server (RPMs) |
rhel-7-server-rpms | Red Hat OpenShift Enterprise 3.2 (RPMs) | rhel-7-server-ose-3.2-rpms
| Red Hat Enterprise Linux 7 Server - Extras (RPMs) | rhel-7-server-extras-rpms

|====

// :align: center
.Availability Zones in US-East-1
|====
^|Availibility Zones

^| us-east-1a
^| us-east-1d
^| us-east-1e

|====

.Elastic Load Balancers
|====
^|ELB ^| Assigned Instances

| openshift-master.sysdeseng.com | master01-3
| internal-openshift-master.sysdeseng.com | master01-3
| *.apps.sysdeseng.com | infra-nodes01-2
|====

Both the internal-openshift-master ELB and the openshift-master both utilize the OpenShift Master API port for communication.  The internal-openshift-master ELB uses the private subnets for internal cluster communication with the API more secure.  The openshift-master ELB is used for externally accessing the OpenShift environment through the API or the web interface. The openshift-master ELB uses the public subnets to allow communication from anywhere.  The *.apps ELB uses the public subnets and maps to infrastructure nodes.  The infrastrucutre nodes run the router pod which then directs traffic directly from the outside world into OpenShift pods with external routes defined.

=== Tooling Prerequisites
As mentioned in the previous section, there are two methods for provisioning the infrastructure. This section describes how the environment should be configured to use either the bash method or the Ansible method to provision the infrastructure. In both cases, Ansible will be used to provision OpenShift Container Platform after the infrastructure has been provisioned.

==== Ansible Setup (Required for both methods)

[subs=+quotes]
----
$ *rpm -qa | grep python-2.7*
$ *subscription-manager repos --enable rhel-7-server-optional-rpms*
$ *rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm*
$ *yum -y install ansible1.9.noarch*
$ *yum -y install python2-boto*
$ *yum -y install git*
$ *yum -y install python-click*
$ *yum -y install python-netaddr*
----

NOTE: The Extra Packages for Enterprise Linux (EPEL) repository is being called here. While it is not explicitly supported by Red Hat, it is how we obtain ansible.

==== Bash Setup (required if provisioning the infrastructure with the Bash scripts)

[subs=+quotes]
----
$ *yum install -y awscli.noarch*
$ *yum install -y jq*
----

Once the awscli packages have been installed, the AWS CLI needs to be configured. To configure the AWS Cli peform the following

[subs=+quotes]
----------------------------------------------------------------------
$ *aws configure*
AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE
AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
Default region name [None]: us-east-1
Default output format [None]: ENTER
----------------------------------------------------------------------

At this point the environment that you are working out of should be configured to provision the infrastructure.

==== Git Repository

===== GitHub Repositories
The code in the two repositories referenced below handles the installation of OpenShift and
the accompanying infrastructure. We clone both the Reference Architecture repository
and the OpenShift Ansible repository.  We check out a specific branch within the Openshift
Ansible repository to ensure the code in the repository matches any references within the
document but also that the code has been tested on both the Bash scripts and Ansible playbooks
by the Referance Architecture team.

The directories for these repositories are expected to exist in the same
subdirectory. An example tree structure is below:

[subs=+quotes]
----
$ *tree /home/user/git/*

... content abbreviated ...

|-- openshift-ansible-contrib
|-- openshift-ansible
----

If the directory structure does not match the above the installation will fail
because the openshift-ansible-contrib relies on the openshift-ansible playbooks
for the installation of specific components.

===== Directory Setup

[subs=+quotes]
----
$ *cd /home/user/git*
$ *git clone https://github.com/openshift/openshift-ansible-contrib.git*
$ *git clone https://github.com/openshift/openshift-ansible.git*
$ *cd openshift-ansible*
$ *git checkout enterprise-3.2*
----

==== Permissions for Amazon Web Services

The deployment of OpenShift requires a user that has the proper permissions by the
 AWS IAM administrator. The user must be able to create accounts, S3 buckets,
roles, policies, Route53 entries, and deploy ELBs and EC2 instances. It is also helpful to have delete permissions in order to be able to redeploy the environment while testing.

===== AWS Configuration
The AWS Access Key ID and Secret Access Key must be exported on the workstation
executing the Ansible playbooks. This account must have the ability to create IAM
users, IAM Policies, and S3 buckets.

To export the Access Key ID and Secret perform the following

[subs=+quotes]
----
$ *export AWS_ACCESS_KEY_ID=foo*
$ *export AWS_SECRET_ACCESS_KEY=bar*
----

===== SSH Configuration
The SSH configuration must be in place before launching instances into AWS. If the
configuration is not in place the OpenShift installation will fail because Ansible
will not be able to connect to the instances.  If using the bash installation
which will create a SSH key enter the path in which the SSH key will be created.

[subs=+quotes]
----
$ *cat /home/user/.ssh/config*

Host bastion
     Hostname                 bastion.sysdeseng.com
     StrictHostKeyChecking      no
     ProxyCommand               none
     CheckHostIP                no
     ForwardAgent               yes
     IdentityFile               /home/user/.ssh/OSE-key.pem

Host *.sysdeseng.com
     ProxyCommand               ssh ec2-user@bastion -W %h:%p
     IdentityFile               /home/user/.ssh/OSE-key.pem
----

.SSH Configuration
|====
^|Option ^| Purpose

| Host Bastion | Configuration Alias
| Hostname | Hostname of the bastion instance
| StrictHostKeyChecking | Automatically add new host keys to known host file
| ProxyCommand | Not required for the bastion
| CheckHostIP | Key checking is against hostname rather than IP
| ForwardAgent | Used to forward the SSH connection
| IdentityFile | Key used to access bastion instance
| Host *.sysdeseng.com | Wildcard for all *.sysdeseng instances
| ProxyCommand | SSH command used to jump from the bastion host to another host in the environment
| IdentityFile | Key used for all *.sysdeseng instances
|====

// vim: set syntax=asciidoc:
